import torch
import torchvision
from torch import nn
import torchvision.datasets as dataset
from torchvision.utils import make_grid
import torchvision.transforms as transforms
import os
import numpy as np
from VAE import AutoEncoder

batch_size  =   256
device      =   "cuda:0" if torch.cuda.is_available() else "cpu"

data_set = dataset.ImageFolder(root="/Users/martinleterroir/Desktop/Objectif Moi/Completions/Website_Portfolio/Datasets/CelebA", transform=transforms.ToTensor())
data_loader = torch.utils.data.DataLoader(dataset=data_set,
                                          batch_size=batch_size,
                                          shuffle=True, num_workers=0)

AE = AutoEncoder().to(device)

def init_weights(m):
    """
    Initialising Weights From a Xavier Uniform Distribution
    Inputs :
        -   m   :   The Layers Objects of The Model
    """
    if type(m) == nn.Linear:
        torch.nn.init.xavier_uniform_(m.weight)

if not os.path.exists("model_path"):    #   Creating the folder to store the Model's Weights
    os.mkdir("model_path")
    AE.apply(init_weights)
    AE.logvar.weight = torch.nn.Parameter(torch.zeros_like(AE.logvar.weight))

else:                                   #   Or Loading Them if existing
    AE.load_state_dict(torch.load("model_path/VAEKinCelebAv0.1.pt"))

def loss_function(Recon, X, mean, logstd):
    """
    Traditional Cost Function for VAE -> KLD + Reconstruction Loss

    Inputs :
        -   Recon   :   The Reconstruction      ==> Tensor -> (batch_size, 4096)
        -   X       :   The Ground Truth Image  ==> Tensor -> (batch_size, 4096)
        -   mean    :   The Encoded Mean        ==> Tensor -> (batch_size, 100)
        -   logstd  :   The Encoded LogStd      ==> Tensor -> (batch_size, 100)
    
    Returns :
        -   Cost    :   The Cost for The Batch  ==> int
    """
    MSE = nn.functional.mse_loss(Recon,X,reduction="sum")
    KLD = 0.5 * torch.sum(mean.pow(2) +torch.exp(logstd) - 1 - logstd)

    return KLD+MSE

criterion   =   loss_function
lr          =   0.0002                                      #   Defining the learning rate
optimizer   =   torch.optim.Adam(AE.parameters(), lr=lr)    #   Creating the Optimizer (Here ADAM Optimizer)

noises      =   torch.randn(5, 100, requires_grad=False)    #   Creating Noises Vectors to keep track of visual progress throught the training
epochs      =   100

if __name__ == "__main__":
    AE.train()
    best_loss   =   np.inf          #   Initialize The Best Loss as "Infinity"
    for epoch in range(epochs):
        av_loss = 0                 #   Initialize The Average Epoch Loss

        for batch_idx, (X,_) in enumerate(data_loader): #   Iterating through the DataLoader
            optimizer.zero_grad()

            X   =   X.to(device)
            y_hat, mean, logstd =   AE(X)   #   Run The Model on The Batch

            with torch.enable_grad():
                loss = loss_function(y_hat, X.view(-1,4096), mean, logstd)  #   Computing The Cost
                loss.backward()                                             #   Computing The Gradients
                optimizer.step()                                            #   Updating The Model's Weights
            av_loss +=  loss.data.item()

            if batch_idx%100 == 0:
                print("batch {}. loss : {:.5f}".format(batch_idx+1, av_loss/(batch_idx+1)))
        if av_loss < best_loss: #   If the model as ameliorated it's predictions then we store the weigths
            torch.save(AE.state_dict(), "models/VAEKinCelebAv0.1.pt")

        with torch.no_grad():   #   Saving Images generated by the Model, at each Epoch, through the training process
            imgs    =   AE.decoder(noises).cpu().detach().reshape(-1, 1, 64, 64)
            grid    =   make_grid(imgs, nrow = 4)
            img     =   torchvision.utils.save_image(grid, fp="generations_through_training/generations_epoch_{}.jpg".format(epoch))
        print("epoch {}, loss : {:.5f}".format(epoch+1, av_loss/len(data_loader)))